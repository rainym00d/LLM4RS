{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import time\n",
    "import itertools\n",
    "import copy\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('max_colwidth',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"/News\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read  Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIND_dev_news_df = pd.read_csv(\"../Dataset/MINDsmall_dev/news.tsv\", header=None, delimiter=\"\\t\")\n",
    "MIND_dev_news_df.columns = [\"newsid\",\"category\",\"subcategory\",\"title\",\"abstract\",\"url\",\"title_entities\",\"abstract_entities\"]\n",
    "MIND_dev_news_df.drop(['url','title_entities','abstract_entities'], axis=1, inplace=True)\n",
    "MIND_dev_news_df\n",
    "(MIND_dev_news_df.isna().sum()/MIND_dev_news_df.shape[0]).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIND_dev_news_df_fliter = MIND_dev_news_df.dropna().reset_index(drop=True)\n",
    "MIND_dev_news_df_fliter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_newsid_list = pd.concat([MIND_dev_news_df, MIND_dev_news_df_fliter]).drop_duplicates([\"newsid\"],keep=False).newsid.values.tolist()\n",
    "drop_newsid_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIND_dev_df = pd.read_csv(\"../Dataset/MINDsmall_dev/behaviors.tsv\", header=None, delimiter=\"\\t\")\n",
    "MIND_dev_df.columns = [\"impressionid\",\"userid\",\"time\",\"history\",\"impression\"]\n",
    "MIND_dev_df[\"history\"] = MIND_dev_df[\"history\"].apply(lambda x: str(x).split(' '))\n",
    "MIND_dev_df[\"impression\"] = MIND_dev_df[\"impression\"].apply(lambda x: str(x).split(' '))\n",
    "MIND_dev_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Fliter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_impression_and_history(row):\n",
    "    impression_list = []\n",
    "    impression_pos_list = []\n",
    "    label_list = []\n",
    "    flag = 0\n",
    "    for i in row.impression:\n",
    "        impression, label = i.split(\"-\")\n",
    "        if impression in drop_newsid_list:\n",
    "            continue\n",
    "        label = int(label)\n",
    "        if label == 1:\n",
    "            impression_pos_list.append(impression)\n",
    "            if flag == 1:\n",
    "                continue\n",
    "            else:\n",
    "                impression_list.append(impression)\n",
    "                label_list.append(label)\n",
    "                flag=1\n",
    "        else:\n",
    "            impression_list.append(impression)\n",
    "            label_list.append(label)\n",
    "    \n",
    "    if 1 not in label_list:\n",
    "        pos_target = -1\n",
    "    else:\n",
    "        pos_target = impression_list[label_list.index(1)]\n",
    "        \n",
    "    history_list = copy.deepcopy(row.history)\n",
    "    for i in row.history:\n",
    "        if i in drop_newsid_list:\n",
    "            history_list.remove(i)\n",
    "     \n",
    "    return [impression_list, label_list, pos_target, history_list, impression_pos_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIND_dev_df[[\"impression_list\", \"label_list\", \"pos_target\", \"history_list\", \"impression_pos_list\"]] = MIND_dev_df.apply(get_clean_impression_and_history, axis=1, result_type=\"expand\")\n",
    "MIND_dev_df.drop(['time','impression','history'], axis=1, inplace=True)\n",
    "MIND_dev_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impression_list = MIND_dev_df[\"impression_pos_list\"].values.tolist()\n",
    "history_list = MIND_dev_df[\"history_list\"].values.tolist()\n",
    "impression_list = list(itertools.chain(*impression_list))\n",
    "history_list = list(itertools.chain(*history_list))\n",
    "impression_list = pd.Series(impression_list + history_list)\n",
    "item_pop = impression_list.value_counts().rename_axis(\"itemid\").reset_index(name=\"pop\")\n",
    "item_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIND_dev_df = MIND_dev_df[MIND_dev_df[\"pos_target\"]!=-1].reset_index(drop=True)\n",
    "MIND_dev_df[\"history_len\"] = MIND_dev_df[\"history_list\"].apply(lambda x: len(x))\n",
    "MIND_dev_df[\"impression_len\"] = MIND_dev_df[\"impression_list\"].apply(lambda x: len(x))\n",
    "MIND_dev_df_fliter = MIND_dev_df[(MIND_dev_df[\"history_len\"]>=10) & (MIND_dev_df[\"impression_len\"]>=10)].reset_index(drop=True)\n",
    "MIND_dev_df_fliter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncat_data(row, n_candidate=10, n_history=10):\n",
    "    # trunct candiadte\n",
    "    cache = copy.deepcopy(row.impression_list)\n",
    "    cache.remove(row.pos_target)\n",
    "    neg_target = cache.pop(0)\n",
    "    candidate = [row.pos_target] + [neg_target] + cache[:8]\n",
    "    # trunct history\n",
    "    history = row.history_list[-n_history:]\n",
    "    \n",
    "    return neg_target, candidate, history\n",
    "\n",
    "MIND_dev_df_fliter[[\"neg_target\", \"full_candidate\", \"full_history\"]] = MIND_dev_df_fliter.apply(truncat_data, n_candidate=10, n_history=10, axis=1, result_type=\"expand\")\n",
    "MIND_dev_df_fliter.shape[0]\n",
    "MIND_dev_df_fliter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIND_dev_df_fliter_new = MIND_dev_df_fliter[:10000].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user_set = set(MIND_dev_df_fliter_new[\"userid\"].values.tolist())\n",
    "test_item_set = set(itertools.chain.from_iterable(MIND_dev_df_fliter_new[\"full_candidate\"].values.tolist())) | set(itertools.chain.from_iterable(MIND_dev_df_fliter_new[\"full_history\"].values.tolist()))\n",
    "len(set(itertools.chain.from_iterable(MIND_dev_df_fliter_new[\"full_candidate\"].values.tolist())))\n",
    "len(test_user_set)\n",
    "len(test_item_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "user_le = preprocessing.LabelEncoder()\n",
    "user_le.fit(list(test_user_set))\n",
    "print(\"user id unique nums:\", len(user_le.classes_))\n",
    "\n",
    "item_le = preprocessing.LabelEncoder()\n",
    "item_le.fit(list(test_item_set))\n",
    "print(\"item id unique nums:\", len(item_le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_pop = item_pop[item_pop[\"itemid\"].isin(list(set(itertools.chain.from_iterable(MIND_dev_df_fliter_new[\"full_candidate\"].values.tolist()))))].reset_index(drop=True)\n",
    "item_pop[\"itemid\"] = pd.Series(item_le.transform(item_pop['itemid']))\n",
    "item_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIND_dev_df_fliter_new[\"userid\"] = pd.Series(user_le.transform(MIND_dev_df_fliter_new['userid']))\n",
    "MIND_dev_df_fliter_new[\"full_candidate\"] = MIND_dev_df_fliter_new[\"full_candidate\"].apply(lambda x: list(item_le.transform(x)))\n",
    "MIND_dev_df_fliter_new[\"full_history\"] = MIND_dev_df_fliter_new[\"full_history\"].apply(lambda x: list(item_le.transform(x)))\n",
    "MIND_dev_df_fliter_new[\"pos_id_target\"] = pd.Series(item_le.transform(MIND_dev_df_fliter_new['pos_target']))\n",
    "MIND_dev_df_fliter_new[\"neg_id_target\"] = pd.Series(item_le.transform(MIND_dev_df_fliter_new['neg_target']))\n",
    "\n",
    "MIND_dev_df_fliter_new\n",
    "MIND_dev_df_fliter_new.to_csv(f\"./Dataset/{dataset_name}/processed/MIND_dev_df_fliter.csv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Gnerate Test Data for Top-K Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sub_history_and_candidate(row, n_candidate=10, n_history=10):\n",
    "    cand_cache = list(copy.deepcopy(row.full_candidate))\n",
    "    cand_cache.remove(row.pos_id_target)\n",
    "    cand_cache.remove(row.neg_id_target)\n",
    "    candidate = [int(row.pos_id_target)] + [int(row.neg_id_target)] + cand_cache[:n_candidate-2]\n",
    "    random.shuffle(candidate)\n",
    "    pos_target_index = candidate.index(row.pos_id_target)\n",
    "    history = row.full_history[-n_history : ]\n",
    "    \n",
    "    return candidate, history, pos_target_index\n",
    "\n",
    "def get_pairwise_data(row):\n",
    "    candidate = row.itemid_candidate\n",
    "    pos = candidate[row.pos_target_index]\n",
    "    neg_list = copy.deepcopy(candidate)\n",
    "    neg_list.remove(pos)\n",
    "    pair_list = []\n",
    "    answer_list = []\n",
    "    for neg in neg_list:\n",
    "        pair = [pos, neg]\n",
    "        random.shuffle(pair)\n",
    "        answer = pair.index(pos)\n",
    "        pair_list.append(pair)\n",
    "        answer_list.append(answer)\n",
    "    \n",
    "    return pair_list, answer_list\n",
    "\n",
    "def get_topk_final_data(df):\n",
    "    for n_candidate in [2,5,10]:\n",
    "        for n_history in [1,3,5,10]:\n",
    "            print(f\"n_candidate:{n_candidate} ; n_history{n_history}\")\n",
    "            LLM_top1_data = copy.deepcopy(df)\n",
    "            random.seed(2023)\n",
    "            LLM_top1_data[[\"itemid_candidate\", \"itemid_history\", \"pos_target_index\"]] = LLM_top1_data.apply(get_sub_history_and_candidate, n_candidate=n_candidate, n_history=n_history, axis=1, result_type=\"expand\")\n",
    "            LLM_top1_data = LLM_top1_data.sample(frac=1.0, random_state=2023).reset_index(drop=True)\n",
    "            LLM_top1_data[[\"pair_itemid_candidate\", \"pair_pos_target_index\"]] = LLM_top1_data.apply(get_pairwise_data, axis=1, result_type=\"expand\")\n",
    "            LLM_top1_data.to_csv(f\"./Dataset/{dataset_name}/LLM/topk_candidate@{n_candidate}_history@{n_history}.csv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_topk_final_data(MIND_dev_df_fliter_new)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Generate Datamaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIND_dev_news_df_fliter = MIND_dev_news_df_fliter[MIND_dev_news_df_fliter[\"newsid\"].isin(test_item_set)].reset_index(drop=True)\n",
    "MIND_dev_news_df_fliter\n",
    "(MIND_dev_news_df_fliter.isna().sum()/MIND_dev_news_df_fliter.shape[0]).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIND_dev_news_df_fliter[\"itemid\"] = pd.Series(item_le.transform(MIND_dev_news_df_fliter['newsid']))\n",
    "MIND_dev_news_df_fliter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIND_dev_news_df_fliter.to_csv(f\"./Dataset/{dataset_name}/processed/full_item.csv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_name(s):\n",
    "    s = s.replace(\"&amp;\", \"&\")\n",
    "    s = s.replace(\"  \", \" \")\n",
    "    s = s.replace(\"\\n\", \" \")\n",
    "    s = s.replace(\"\\\\\", \" \")\n",
    "    return s\n",
    "MIND_dev_news_df_fliter[\"title\"] = MIND_dev_news_df_fliter[\"title\"].apply(lambda x: process_name(x))\n",
    "MIND_dev_news_df_fliter[\"abstract\"] = MIND_dev_news_df_fliter[\"abstract\"].apply(lambda x: process_name(x))\n",
    "\n",
    "\n",
    "id2item_dict = MIND_dev_news_df_fliter.set_index(\"itemid\")[\"title\"].to_dict()\n",
    "id2item_dict\n",
    "item2id_dict = MIND_dev_news_df_fliter.set_index(\"title\")[\"itemid\"].to_dict()\n",
    "item2id_dict\n",
    "\n",
    "datamaps = {}\n",
    "datamaps[\"id2item_dict\"] = id2item_dict\n",
    "datamaps[\"item2id_dict\"] = item2id_dict\n",
    "\n",
    "import json\n",
    "json_str = json.dumps(datamaps)\n",
    "with open(f\"./Dataset/{dataset_name}/LLM/title_datamaps.json\", 'w') as out:\n",
    "    out.write(json_str)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2item_dict = MIND_dev_news_df_fliter.set_index(\"itemid\")[\"abstract\"].to_dict()\n",
    "id2item_dict\n",
    "item2id_dict = MIND_dev_news_df_fliter.set_index(\"abstract\")[\"itemid\"].to_dict()\n",
    "item2id_dict\n",
    "\n",
    "datamaps = {}\n",
    "datamaps[\"id2item_dict\"] = id2item_dict\n",
    "datamaps[\"item2id_dict\"] = item2id_dict\n",
    "\n",
    "import json\n",
    "json_str = json.dumps(datamaps)\n",
    "with open(f\"./Dataset/{dataset_name}/LLM/abstract_datamaps.json\", 'w') as out:\n",
    "    out.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item2pop_dict = item_pop.set_index(\"itemid\")[\"pop\"].to_dict()\n",
    "for i in id2item_dict.keys():\n",
    "    if i not in item2pop_dict.keys():\n",
    "        item2pop_dict[i] = 0\n",
    "item2pop_dict\n",
    "\n",
    "json_str = json.dumps(item2pop_dict)\n",
    "with open(f\"./Dataset/{dataset_name}/LLM/popularity_datamaps.json\", 'w') as out:\n",
    "    out.write(json_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of Loading Final Evaluation Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>itemid_history</th>\n",
       "      <th>pos_target_index</th>\n",
       "      <th>itemid_candidate</th>\n",
       "      <th>pair_itemid_candidate</th>\n",
       "      <th>pair_pos_target_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2223</td>\n",
       "      <td>[315, 4611, 11549, 9355, 6963]</td>\n",
       "      <td>3</td>\n",
       "      <td>[10805, 5205, 1256, 11960, 8488]</td>\n",
       "      <td>[[11960, 10805], [11960, 5205], [1256, 11960], [11960, 8488]]</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6951</td>\n",
       "      <td>[12195, 11577, 7086, 89, 3786]</td>\n",
       "      <td>3</td>\n",
       "      <td>[9766, 7805, 5777, 1374, 1663]</td>\n",
       "      <td>[[1374, 9766], [7805, 1374], [1374, 5777], [1663, 1374]]</td>\n",
       "      <td>[0, 1, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8289</td>\n",
       "      <td>[12301, 6691, 2020, 5144, 11053]</td>\n",
       "      <td>0</td>\n",
       "      <td>[11436, 5073, 3589, 11386, 9675]</td>\n",
       "      <td>[[11436, 5073], [11436, 3589], [11436, 11386], [9675, 11436]]</td>\n",
       "      <td>[0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6217</td>\n",
       "      <td>[4806, 7064, 468, 8379, 7139]</td>\n",
       "      <td>4</td>\n",
       "      <td>[9673, 3219, 11257, 8609, 4579]</td>\n",
       "      <td>[[9673, 4579], [4579, 3219], [11257, 4579], [4579, 8609]]</td>\n",
       "      <td>[1, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8188</td>\n",
       "      <td>[3457, 5503, 11137, 4090, 4098]</td>\n",
       "      <td>4</td>\n",
       "      <td>[5044, 6230, 3689, 11161, 4739]</td>\n",
       "      <td>[[4739, 5044], [6230, 4739], [4739, 3689], [4739, 11161]]</td>\n",
       "      <td>[0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>6047</td>\n",
       "      <td>[6392, 2427, 10769, 10951, 10751]</td>\n",
       "      <td>3</td>\n",
       "      <td>[8704, 8855, 7041, 7981, 11518]</td>\n",
       "      <td>[[7981, 8704], [8855, 7981], [7981, 7041], [11518, 7981]]</td>\n",
       "      <td>[0, 1, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>8165</td>\n",
       "      <td>[5925, 1366, 5742, 4277, 6735]</td>\n",
       "      <td>3</td>\n",
       "      <td>[9252, 5777, 10513, 9843, 7654]</td>\n",
       "      <td>[[9843, 9252], [9843, 5777], [9843, 10513], [9843, 7654]]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>6227</td>\n",
       "      <td>[6994, 8853, 11844, 6063, 1286]</td>\n",
       "      <td>0</td>\n",
       "      <td>[4757, 10240, 7886, 10350, 7529]</td>\n",
       "      <td>[[4757, 10240], [7886, 4757], [4757, 10350], [4757, 7529]]</td>\n",
       "      <td>[0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>4203</td>\n",
       "      <td>[7771, 5144, 11482, 9193, 12196]</td>\n",
       "      <td>3</td>\n",
       "      <td>[9641, 11518, 6077, 2445, 11870]</td>\n",
       "      <td>[[9641, 2445], [2445, 11518], [6077, 2445], [2445, 11870]]</td>\n",
       "      <td>[1, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>5000</td>\n",
       "      <td>[3063, 884, 11577, 6030, 9407]</td>\n",
       "      <td>3</td>\n",
       "      <td>[10476, 3948, 5447, 10342, 2968]</td>\n",
       "      <td>[[10476, 10342], [10342, 3948], [5447, 10342], [2968, 10342]]</td>\n",
       "      <td>[1, 0, 1, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      userid                     itemid_history  pos_target_index  \\\n",
       "0       2223     [315, 4611, 11549, 9355, 6963]                 3   \n",
       "1       6951     [12195, 11577, 7086, 89, 3786]                 3   \n",
       "2       8289   [12301, 6691, 2020, 5144, 11053]                 0   \n",
       "3       6217      [4806, 7064, 468, 8379, 7139]                 4   \n",
       "4       8188    [3457, 5503, 11137, 4090, 4098]                 4   \n",
       "...      ...                                ...               ...   \n",
       "9995    6047  [6392, 2427, 10769, 10951, 10751]                 3   \n",
       "9996    8165     [5925, 1366, 5742, 4277, 6735]                 3   \n",
       "9997    6227    [6994, 8853, 11844, 6063, 1286]                 0   \n",
       "9998    4203   [7771, 5144, 11482, 9193, 12196]                 3   \n",
       "9999    5000     [3063, 884, 11577, 6030, 9407]                 3   \n",
       "\n",
       "                      itemid_candidate  \\\n",
       "0     [10805, 5205, 1256, 11960, 8488]   \n",
       "1       [9766, 7805, 5777, 1374, 1663]   \n",
       "2     [11436, 5073, 3589, 11386, 9675]   \n",
       "3      [9673, 3219, 11257, 8609, 4579]   \n",
       "4      [5044, 6230, 3689, 11161, 4739]   \n",
       "...                                ...   \n",
       "9995   [8704, 8855, 7041, 7981, 11518]   \n",
       "9996   [9252, 5777, 10513, 9843, 7654]   \n",
       "9997  [4757, 10240, 7886, 10350, 7529]   \n",
       "9998  [9641, 11518, 6077, 2445, 11870]   \n",
       "9999  [10476, 3948, 5447, 10342, 2968]   \n",
       "\n",
       "                                              pair_itemid_candidate  \\\n",
       "0     [[11960, 10805], [11960, 5205], [1256, 11960], [11960, 8488]]   \n",
       "1          [[1374, 9766], [7805, 1374], [1374, 5777], [1663, 1374]]   \n",
       "2     [[11436, 5073], [11436, 3589], [11436, 11386], [9675, 11436]]   \n",
       "3         [[9673, 4579], [4579, 3219], [11257, 4579], [4579, 8609]]   \n",
       "4         [[4739, 5044], [6230, 4739], [4739, 3689], [4739, 11161]]   \n",
       "...                                                             ...   \n",
       "9995      [[7981, 8704], [8855, 7981], [7981, 7041], [11518, 7981]]   \n",
       "9996      [[9843, 9252], [9843, 5777], [9843, 10513], [9843, 7654]]   \n",
       "9997     [[4757, 10240], [7886, 4757], [4757, 10350], [4757, 7529]]   \n",
       "9998     [[9641, 2445], [2445, 11518], [6077, 2445], [2445, 11870]]   \n",
       "9999  [[10476, 10342], [10342, 3948], [5447, 10342], [2968, 10342]]   \n",
       "\n",
       "     pair_pos_target_index  \n",
       "0             [0, 0, 1, 0]  \n",
       "1             [0, 1, 0, 1]  \n",
       "2             [0, 0, 0, 1]  \n",
       "3             [1, 0, 1, 0]  \n",
       "4             [0, 1, 0, 0]  \n",
       "...                    ...  \n",
       "9995          [0, 1, 0, 1]  \n",
       "9996          [0, 0, 0, 0]  \n",
       "9997          [0, 1, 0, 0]  \n",
       "9998          [1, 0, 1, 0]  \n",
       "9999          [1, 0, 1, 1]  \n",
       "\n",
       "[10000 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_example_df = pd.read_csv(f\"./Dataset/{dataset_name}/LLM/topk_candidate@5_history@5.csv\", delimiter=\"\\t\")\n",
    "read_example_df = read_example_df[[\"userid\", \"itemid_history\", \"pos_target_index\", \"itemid_candidate\", \"pair_itemid_candidate\", \"pair_pos_target_index\"]]\n",
    "for col in ['itemid_history', 'itemid_candidate', \"pair_itemid_candidate\", \"pair_pos_target_index\"]:\n",
    "    read_example_df[col] = read_example_df[col].apply(lambda x: eval(x))\n",
    "    \n",
    "read_example_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10805,  5205,  1256, 11960,  8488],\n",
       "       [ 9766,  7805,  5777,  1374,  1663],\n",
       "       [11436,  5073,  3589, 11386,  9675],\n",
       "       ...,\n",
       "       [ 4757, 10240,  7886, 10350,  7529],\n",
       "       [ 9641, 11518,  6077,  2445, 11870],\n",
       "       [10476,  3948,  5447, 10342,  2968]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_example_df = pd.read_csv(f\"./Dataset/{dataset_name}/LLM/topk_candidate@5_history@5.csv\", delimiter=\"\\t\")\n",
    "read_example_df = read_example_df[[\"userid\", \"pos_target_index\", \"itemid_candidate\"]]\n",
    "read_example_df[\"itemid_candidate\"] = read_example_df[\"itemid_candidate\"].apply(lambda x: x[1:-1])\n",
    "candidate = read_example_df['itemid_candidate'].str.split(',', expand=True)\n",
    "for col in candidate.columns:\n",
    "    candidate[col] = candidate[col].apply(lambda x: int(x))\n",
    "candidate.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_1_6",
   "language": "python",
   "name": "torch_1_6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
