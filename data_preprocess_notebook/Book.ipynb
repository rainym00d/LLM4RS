{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import time\n",
    "import itertools\n",
    "import copy\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('max_colwidth',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"/Book\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_df = pd.read_csv('../Dataset/Amazon_Books/Amazon_Books.item',sep=\"\\t\",encoding=\"latin-1\")\n",
    "item_df.columns = [\"itemid\",\"sales_type\",\"sales_rank\",\"categories\",\"title\",\"price\",\"brand\"]\n",
    "item_df.shape[0]\n",
    "item_df = item_df[item_df[\"sales_type\"]==\"Books\"].reset_index(drop=True)\n",
    "item_df\n",
    "(item_df.isna().sum()/item_df.shape[0]).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_df.drop([\"categories\",\"brand\",\"sales_type\",\"sales_rank\",\"price\"], axis=1, inplace=True)\n",
    "item_df = item_df.dropna().reset_index(drop=True) # fliter no title\n",
    "item_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df = pd.read_csv('../Dataset/Amazon_Books/Amazon_Books.inter',sep=\"\\t\")\n",
    "rating_df.columns = [\"userid\",\"itemid\",\"rating\",\"timestamp\"]\n",
    "rating_df = rating_df[rating_df[\"itemid\"].isin(item_df.itemid.tolist())].reset_index(drop=True) # fliter no title\n",
    "rating_df\n",
    "(rating_df.isna().sum()/rating_df.shape[0]).sort_values(ascending=False)\n",
    "rating_df[\"userid\"].nunique()\n",
    "rating_df[\"itemid\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_interactions_count = rating_df[[\"userid\",\"itemid\"]].groupby([\"itemid\"]).count()\n",
    "item_interactions_count.columns = [\"count\"]\n",
    "item_interactions_count.sort_values([\"count\"] , inplace=True, ascending=False)\n",
    "item_interactions_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_interactions_count[:10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Fliter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_title_exist_idset = item_interactions_count[:10000].index.tolist()\n",
    "rating_df_fliter = rating_df[rating_df[\"itemid\"].isin(item_title_exist_idset)].reset_index(drop=True)\n",
    "rating_df_fliter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df_fliter[\"rating\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df_fliter[\"label\"] = rating_df_fliter[\"rating\"].apply(lambda x: 1 if x>=4 else 0)\n",
    "rating_df_fliter\n",
    "rating_df_fliter[rating_df_fliter[\"label\"]==1].shape[0] / rating_df_fliter.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_pop = rating_df_fliter[rating_df_fliter[\"label\"]==1][\"itemid\"].value_counts().rename_axis(\"itemid\").reset_index(name=\"pop\")\n",
    "item_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df_fliter.sort_values([\"userid\", \"timestamp\"] , inplace=True, ascending=True) \n",
    "rating_df_fliter = rating_df_fliter.reset_index(drop=True)\n",
    "sequence_df = rating_df_fliter.groupby(['userid']).agg(\n",
    "    itemid_seq=(\"itemid\", list),\n",
    "    label_seq=(\"label\", list)\n",
    ").reset_index()\n",
    "sequence_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seq(row):\n",
    "    pos_seq = []\n",
    "    neg_seq = []\n",
    "    for i in range(len(row.label_seq)):\n",
    "        if row.label_seq[i]==1:\n",
    "            pos_seq.append(row.itemid_seq[i])\n",
    "        else:\n",
    "            neg_seq.append(row.itemid_seq[i])\n",
    "    return pos_seq, neg_seq, len(row.itemid_seq), len(pos_seq), len(neg_seq)\n",
    "\n",
    "sequence_df[[\"pos_seq\",\"neg_seq\", \"seq_length\", \"pos_seq_length\", \"neg_seq_length\"]] = sequence_df.apply(get_seq, axis=1, result_type=\"expand\") \n",
    "sequence_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_df[(sequence_df[\"pos_seq_length\"]>=6) & (sequence_df[\"neg_seq_length\"]>=6)].shape[0]\n",
    "sequence_df[(sequence_df[\"pos_seq_length\"]>=12) & (sequence_df[\"neg_seq_length\"]>=10)].shape[0]\n",
    "sequence_df[(sequence_df[\"pos_seq_length\"]>=13) & (sequence_df[\"neg_seq_length\"]>=10)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_df_fliter = sequence_df[(sequence_df[\"pos_seq_length\"]>=13) & (sequence_df[\"neg_seq_length\"]>=10)].reset_index(drop=True)\n",
    "item_df = item_df[item_df[\"itemid\"].isin(list(itertools.chain.from_iterable(sequence_df_fliter[\"itemid_seq\"].values.tolist())))].reset_index(drop=True)\n",
    "sequence_df_fliter\n",
    "item_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LabelEncoder \n",
    "from sklearn import preprocessing\n",
    "\n",
    "user_le = preprocessing.LabelEncoder()\n",
    "user_le.fit(sequence_df_fliter['userid'].values.tolist())\n",
    "print(\"user id unique nums:\", len(user_le.classes_))\n",
    "sequence_df_fliter['userid'] = pd.Series(user_le.transform(sequence_df_fliter['userid']))\n",
    "\n",
    "\n",
    "item_le = preprocessing.LabelEncoder()\n",
    "item_le.fit(list(itertools.chain.from_iterable(sequence_df_fliter[\"itemid_seq\"].values.tolist())))\n",
    "print(\"item id unique nums:\", len(item_le.classes_))\n",
    "sequence_df_fliter['pos_seq'] = sequence_df_fliter['pos_seq'].apply(lambda x: list(item_le.transform(x)))\n",
    "sequence_df_fliter['neg_seq'] = sequence_df_fliter['neg_seq'].apply(lambda x: list(item_le.transform(x)))\n",
    "\n",
    "sequence_df_fliter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_pop = item_pop[item_pop[\"itemid\"].isin(list(item_df['itemid'].values.tolist()))].reset_index(drop=True)\n",
    "item_pop[\"itemid\"] = pd.Series(item_le.transform(item_pop['itemid']))\n",
    "\n",
    "item_df[\"itemid\"] = pd.Series(item_le.transform(item_df['itemid']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_df.to_csv(f\"./Dataset/{dataset_name}/processed/full_item_df.csv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Gnerate Test Data for Top-K Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_df(df, n):\n",
    "    df_new = copy.deepcopy(df)\n",
    "    df_new[\"pos_seq\"] = df_new[\"pos_seq\"].apply(lambda x: x[:-n]) \n",
    "    df_new[\"pos_seq_length\"] = df_new[\"pos_seq\"].apply(lambda x:len(x))\n",
    "\n",
    "    return df_new\n",
    "\n",
    "sequence_df_fliter[\"data_index\"] = sequence_df_fliter[\"userid\"].apply(lambda x: 0)\n",
    "sequence_df_fliter_list = [sequence_df_fliter]\n",
    "for i in range(1, 3):\n",
    "    sequence_df_fliter_new = get_new_df(sequence_df_fliter, i)\n",
    "    sequence_df_fliter_new[\"data_index\"] = sequence_df_fliter_new[\"userid\"].apply(lambda x: i)\n",
    "    sequence_df_fliter_list.append(sequence_df_fliter_new)\n",
    "    \n",
    "full_sequence_df = pd.concat(sequence_df_fliter_list).reset_index(drop=True)\n",
    "full_sequence_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(2023)\n",
    "\n",
    "def get_pos_neg_target(row):\n",
    "    return row.pos_seq[-1], row.neg_seq[-1]\n",
    "\n",
    "\n",
    "def get_full_candidate(row, n_candidate):\n",
    "    cache = copy.deepcopy(row.neg_seq)\n",
    "    cache.remove(row.neg_id_target)\n",
    "    candidate = [row.pos_id_target] + [row.neg_id_target] + (random.sample(cache, n_candidate-2))\n",
    "    random.shuffle(candidate)\n",
    "    \n",
    "    return candidate\n",
    "\n",
    "\n",
    "def get_sub_candidate(row, n_candidate):\n",
    "    cand_cache = copy.deepcopy(row.full_candidate)\n",
    "    cand_cache.remove(row.pos_id_target)\n",
    "    cand_cache.remove(row.neg_id_target)\n",
    "    candidate = [row.pos_id_target] + [row.neg_id_target] + (random.sample(list(cand_cache), n_candidate-2))\n",
    "    random.shuffle(candidate)\n",
    "    \n",
    "    return candidate\n",
    "\n",
    "\n",
    "def get_full_history(row, n_history):\n",
    "    history = row.pos_seq[-1-n_history : -1]\n",
    "    return history\n",
    "\n",
    "\n",
    "def get_sub_history(row, n_history):\n",
    "    history = row.full_history[0-n_history : ]\n",
    "    return history\n",
    "\n",
    "def get_pos_target_index(row):\n",
    "    return row[\"itemid_candidate\"].index(row[\"pos_id_target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_sequence_df_new = full_sequence_df[[\"userid\",\"pos_seq\",\"neg_seq\",\"data_index\"]]\n",
    "full_sequence_df_new[[\"pos_id_target\", \"neg_id_target\"]] = full_sequence_df_new.apply(get_pos_neg_target, axis=1, result_type=\"expand\")\n",
    "full_sequence_df_new[\"full_candidate\"] = full_sequence_df_new.apply(get_full_candidate, n_candidate=10, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full_sequence_df_new[\"full_history\"] = full_sequence_df_new.apply(get_full_history, n_history=10, axis=1)\n",
    "full_sequence_df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_sequence_df_new.to_csv(f\"./Dataset/{dataset_name}/processed/full_sequence_df.csv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairwise_data(row):\n",
    "    candidate = row.itemid_candidate\n",
    "    pos = candidate[row.pos_target_index]\n",
    "    neg_list = copy.deepcopy(candidate)\n",
    "    neg_list.remove(pos)\n",
    "    pair_list = []\n",
    "    answer_list = []\n",
    "    for neg in neg_list:\n",
    "        pair = [pos, neg]\n",
    "        random.shuffle(pair)\n",
    "        answer = pair.index(pos)\n",
    "        pair_list.append(pair)\n",
    "        answer_list.append(answer)\n",
    "    \n",
    "    return pair_list, answer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topk_final_data(df):\n",
    "    for n_candidate in [2,5,10]:\n",
    "        for n_history in [1,3,5,10]:\n",
    "            print(f\"n_candidate:{n_candidate} ; n_history{n_history}\")\n",
    "            LLM_top1_data = copy.deepcopy(df)\n",
    "            LLM_top1_data[\"itemid_candidate\"] = LLM_top1_data.apply(get_sub_candidate, n_candidate=n_candidate, axis=1)\n",
    "            LLM_top1_data[\"itemid_history\"] = LLM_top1_data.apply(get_sub_history, n_history=n_history, axis=1)\n",
    "            LLM_top1_data[\"pos_target_index\"] = LLM_top1_data.apply(get_pos_target_index, axis=1)\n",
    "            LLM_top1_data = LLM_top1_data.sample(frac=1.0, random_state=2023).reset_index(drop=True)\n",
    "            LLM_top1_data[[\"pair_itemid_candidate\", \"pair_pos_target_index\"]] = LLM_top1_data.apply(get_pairwise_data, axis=1, result_type=\"expand\")\n",
    "            LLM_top1_data.to_csv(f\"./Dataset/{dataset_name}/LLM/topk_candidate@{n_candidate}_history@{n_history}.csv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_topk_final_data(full_sequence_df_new)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Generate Datamaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_name(s):\n",
    "    s = s.replace(\"&amp;\", \"&\")\n",
    "    s = s.replace(\"  \", \" \")\n",
    "    s = s.replace(\"\\n\", \" \")\n",
    "    s = s.replace(\"\\\\\", \" \")\n",
    "    return s\n",
    "item_df[\"title\"] = item_df[\"title\"].apply(lambda x: process_name(x))\n",
    "item_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2item_dict = item_df.set_index(\"itemid\")[\"title\"].to_dict()\n",
    "id2item_dict\n",
    "item2id_dict = item_df.set_index(\"title\")[\"itemid\"].to_dict()\n",
    "item2id_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamaps = {}\n",
    "datamaps[\"id2item_dict\"] = id2item_dict\n",
    "datamaps[\"item2id_dict\"] = item2id_dict\n",
    "\n",
    "import json\n",
    "json_str = json.dumps(datamaps)\n",
    "with open(f\"./Dataset/{dataset_name}/LLM/datamaps.json\", 'w') as out:\n",
    "    out.write(json_str)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item2pop_dict = item_pop.set_index(\"itemid\")[\"pop\"].to_dict()\n",
    "for i in id2item_dict.keys():\n",
    "    if i not in item2pop_dict.keys():\n",
    "        item2pop_dict[i] = 0\n",
    "item2pop_dict\n",
    "\n",
    "json_str = json.dumps(item2pop_dict)\n",
    "with open(f\"./Dataset/{dataset_name}/LLM/popularity_datamaps.json\", 'w') as out:\n",
    "    out.write(json_str)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of Loading Final Evaluation Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>itemid_history</th>\n",
       "      <th>pos_target_index</th>\n",
       "      <th>itemid_candidate</th>\n",
       "      <th>pair_itemid_candidate</th>\n",
       "      <th>pair_pos_target_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2320</td>\n",
       "      <td>[2155, 1452, 5497, 3648, 372]</td>\n",
       "      <td>3</td>\n",
       "      <td>[4020, 2033, 3152, 8805, 113]</td>\n",
       "      <td>[[4020, 8805], [2033, 8805], [3152, 8805], [113, 8805]]</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>587</td>\n",
       "      <td>[3943, 7409, 3670, 4575, 7972]</td>\n",
       "      <td>3</td>\n",
       "      <td>[2769, 5957, 1958, 6116, 2768]</td>\n",
       "      <td>[[6116, 2769], [6116, 5957], [6116, 1958], [2768, 6116]]</td>\n",
       "      <td>[0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3218</td>\n",
       "      <td>[87, 7417, 109, 7957, 6329]</td>\n",
       "      <td>0</td>\n",
       "      <td>[5548, 8912, 6000, 5207, 4549]</td>\n",
       "      <td>[[8912, 5548], [5548, 6000], [5548, 5207], [5548, 4549]]</td>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3065</td>\n",
       "      <td>[1023, 414, 5346, 5437, 1037]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1208, 4687, 1313, 1184, 4407]</td>\n",
       "      <td>[[1208, 4687], [1208, 1313], [1184, 1208], [4407, 1208]]</td>\n",
       "      <td>[0, 0, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2677</td>\n",
       "      <td>[4486, 1890, 703, 1267, 5135]</td>\n",
       "      <td>4</td>\n",
       "      <td>[2215, 3863, 2815, 1216, 8989]</td>\n",
       "      <td>[[8989, 2215], [3863, 8989], [2815, 8989], [1216, 8989]]</td>\n",
       "      <td>[0, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10264</th>\n",
       "      <td>2429</td>\n",
       "      <td>[5671, 6901, 7839, 2641, 1127]</td>\n",
       "      <td>4</td>\n",
       "      <td>[3903, 9028, 612, 2218, 5541]</td>\n",
       "      <td>[[3903, 5541], [5541, 9028], [5541, 612], [5541, 2218]]</td>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10265</th>\n",
       "      <td>2626</td>\n",
       "      <td>[4589, 6106, 8470, 8536, 6394]</td>\n",
       "      <td>0</td>\n",
       "      <td>[6395, 6393, 7761, 8500, 9252]</td>\n",
       "      <td>[[6393, 6395], [7761, 6395], [8500, 6395], [9252, 6395]]</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10266</th>\n",
       "      <td>2743</td>\n",
       "      <td>[3201, 6, 1256, 2733, 9204]</td>\n",
       "      <td>3</td>\n",
       "      <td>[9055, 2614, 2878, 2237, 2617]</td>\n",
       "      <td>[[9055, 2237], [2237, 2614], [2878, 2237], [2237, 2617]]</td>\n",
       "      <td>[1, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10267</th>\n",
       "      <td>2234</td>\n",
       "      <td>[4673, 4862, 5289, 6937, 379]</td>\n",
       "      <td>4</td>\n",
       "      <td>[55, 2703, 191, 2233, 1513]</td>\n",
       "      <td>[[55, 1513], [2703, 1513], [191, 1513], [2233, 1513]]</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10268</th>\n",
       "      <td>1528</td>\n",
       "      <td>[6443, 4619, 7870, 1106, 4643]</td>\n",
       "      <td>2</td>\n",
       "      <td>[4850, 8556, 4648, 1105, 6980]</td>\n",
       "      <td>[[4648, 4850], [4648, 8556], [4648, 1105], [4648, 6980]]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10269 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       userid                  itemid_history  pos_target_index  \\\n",
       "0        2320   [2155, 1452, 5497, 3648, 372]                 3   \n",
       "1         587  [3943, 7409, 3670, 4575, 7972]                 3   \n",
       "2        3218     [87, 7417, 109, 7957, 6329]                 0   \n",
       "3        3065   [1023, 414, 5346, 5437, 1037]                 0   \n",
       "4        2677   [4486, 1890, 703, 1267, 5135]                 4   \n",
       "...       ...                             ...               ...   \n",
       "10264    2429  [5671, 6901, 7839, 2641, 1127]                 4   \n",
       "10265    2626  [4589, 6106, 8470, 8536, 6394]                 0   \n",
       "10266    2743     [3201, 6, 1256, 2733, 9204]                 3   \n",
       "10267    2234   [4673, 4862, 5289, 6937, 379]                 4   \n",
       "10268    1528  [6443, 4619, 7870, 1106, 4643]                 2   \n",
       "\n",
       "                     itemid_candidate  \\\n",
       "0       [4020, 2033, 3152, 8805, 113]   \n",
       "1      [2769, 5957, 1958, 6116, 2768]   \n",
       "2      [5548, 8912, 6000, 5207, 4549]   \n",
       "3      [1208, 4687, 1313, 1184, 4407]   \n",
       "4      [2215, 3863, 2815, 1216, 8989]   \n",
       "...                               ...   \n",
       "10264   [3903, 9028, 612, 2218, 5541]   \n",
       "10265  [6395, 6393, 7761, 8500, 9252]   \n",
       "10266  [9055, 2614, 2878, 2237, 2617]   \n",
       "10267     [55, 2703, 191, 2233, 1513]   \n",
       "10268  [4850, 8556, 4648, 1105, 6980]   \n",
       "\n",
       "                                          pair_itemid_candidate  \\\n",
       "0       [[4020, 8805], [2033, 8805], [3152, 8805], [113, 8805]]   \n",
       "1      [[6116, 2769], [6116, 5957], [6116, 1958], [2768, 6116]]   \n",
       "2      [[8912, 5548], [5548, 6000], [5548, 5207], [5548, 4549]]   \n",
       "3      [[1208, 4687], [1208, 1313], [1184, 1208], [4407, 1208]]   \n",
       "4      [[8989, 2215], [3863, 8989], [2815, 8989], [1216, 8989]]   \n",
       "...                                                         ...   \n",
       "10264   [[3903, 5541], [5541, 9028], [5541, 612], [5541, 2218]]   \n",
       "10265  [[6393, 6395], [7761, 6395], [8500, 6395], [9252, 6395]]   \n",
       "10266  [[9055, 2237], [2237, 2614], [2878, 2237], [2237, 2617]]   \n",
       "10267     [[55, 1513], [2703, 1513], [191, 1513], [2233, 1513]]   \n",
       "10268  [[4648, 4850], [4648, 8556], [4648, 1105], [4648, 6980]]   \n",
       "\n",
       "      pair_pos_target_index  \n",
       "0              [1, 1, 1, 1]  \n",
       "1              [0, 0, 0, 1]  \n",
       "2              [1, 0, 0, 0]  \n",
       "3              [0, 0, 1, 1]  \n",
       "4              [0, 1, 1, 1]  \n",
       "...                     ...  \n",
       "10264          [1, 0, 0, 0]  \n",
       "10265          [1, 1, 1, 1]  \n",
       "10266          [1, 0, 1, 0]  \n",
       "10267          [1, 1, 1, 1]  \n",
       "10268          [0, 0, 0, 0]  \n",
       "\n",
       "[10269 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_example_df = pd.read_csv(f\"./Dataset/{dataset_name}/LLM/topk_candidate@5_history@5.csv\", delimiter=\"\\t\")\n",
    "read_example_df = read_example_df[[\"userid\", \"itemid_history\", \"pos_target_index\", \"itemid_candidate\", \"pair_itemid_candidate\", \"pair_pos_target_index\"]]\n",
    "for col in ['itemid_history', 'itemid_candidate', \"pair_itemid_candidate\", \"pair_pos_target_index\"]:\n",
    "    read_example_df[col] = read_example_df[col].apply(lambda x: eval(x))\n",
    "    \n",
    "read_example_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4020, 2033, 3152, 8805,  113],\n",
       "       [2769, 5957, 1958, 6116, 2768],\n",
       "       [5548, 8912, 6000, 5207, 4549],\n",
       "       ...,\n",
       "       [9055, 2614, 2878, 2237, 2617],\n",
       "       [  55, 2703,  191, 2233, 1513],\n",
       "       [4850, 8556, 4648, 1105, 6980]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_example_df = pd.read_csv(f\"./Dataset/{dataset_name}/LLM/topk_candidate@5_history@5.csv\", delimiter=\"\\t\")\n",
    "read_example_df = read_example_df[[\"userid\", \"pos_target_index\", \"itemid_candidate\"]]\n",
    "read_example_df[\"itemid_candidate\"] = read_example_df[\"itemid_candidate\"].apply(lambda x: x[1:-1])\n",
    "candidate = read_example_df['itemid_candidate'].str.split(',', expand=True)\n",
    "for col in candidate.columns:\n",
    "    candidate[col] = candidate[col].apply(lambda x: int(x))\n",
    "candidate.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_1_6",
   "language": "python",
   "name": "torch_1_6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
