{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import time\n",
    "import itertools\n",
    "import copy\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('max_colwidth',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"/Music\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_df = pd.read_csv('../Dataset/Amazon_CDs_Vinyl/Amazon_CDs_and_Vinyl.item',sep=\"\\t\",encoding=\"latin-1\")\n",
    "item_df.columns = [\"itemid\",\"title\",\"categories\",\"brand\",\"sales_type\",\"sales_rank\",\"price\"]\n",
    "item_df.shape[0]\n",
    "item_df = item_df[item_df[\"sales_type\"]==\"CDs & Vinyl\"].reset_index(drop=True)\n",
    "item_df\n",
    "(item_df.isna().sum()/item_df.shape[0]).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_df.drop([\"sales_rank\",\"price\"], axis=1, inplace=True)\n",
    "item_df = item_df.dropna().reset_index(drop=True) \n",
    "item_df[\"title\"] = item_df[\"title\"].apply(lambda x: \"-1\" if str(x)[0]==\"<\" else str(x))\n",
    "item_df = item_df[item_df[\"title\"]!=\"-1\"].reset_index(drop=True)\n",
    "item_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df = pd.read_csv('../Dataset/Amazon_CDs_Vinyl/Amazon_CDs_and_Vinyl.inter',sep=\"\\t\")\n",
    "rating_df.columns = [\"userid\",\"itemid\",\"rating\",\"timestamp\"]\n",
    "rating_df = rating_df[rating_df[\"itemid\"].isin(item_df.itemid.tolist())].reset_index(drop=True) # fliter no title\n",
    "rating_df\n",
    "(rating_df.isna().sum()/rating_df.shape[0]).sort_values(ascending=False)\n",
    "rating_df[\"userid\"].nunique()\n",
    "rating_df[\"itemid\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_interactions_count = rating_df[[\"userid\",\"itemid\"]].groupby([\"itemid\"]).count()\n",
    "item_interactions_count.columns = [\"count\"]\n",
    "item_interactions_count.sort_values([\"count\"] , inplace=True, ascending=False)\n",
    "item_interactions_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_interactions_count[:50000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Fliter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_title_exist_idset = item_interactions_count[:50000].index.tolist()\n",
    "rating_df_fliter = rating_df[rating_df[\"itemid\"].isin(item_title_exist_idset)].reset_index(drop=True)\n",
    "rating_df_fliter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df_fliter[\"rating\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df_fliter[\"label\"] = rating_df_fliter[\"rating\"].apply(lambda x: 1 if x>=4 else 0)\n",
    "rating_df_fliter\n",
    "rating_df_fliter[rating_df_fliter[\"label\"]==1].shape[0] / rating_df_fliter.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_pop = rating_df_fliter[rating_df_fliter[\"label\"]==1][\"itemid\"].value_counts().rename_axis(\"itemid\").reset_index(name=\"pop\")\n",
    "item_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df_fliter.sort_values([\"userid\", \"timestamp\"] , inplace=True, ascending=True) \n",
    "rating_df_fliter = rating_df_fliter.reset_index(drop=True)\n",
    "sequence_df = rating_df_fliter.groupby(['userid']).agg(\n",
    "    itemid_seq=(\"itemid\", list),\n",
    "    label_seq=(\"label\", list)\n",
    ").reset_index()\n",
    "sequence_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seq(row):\n",
    "    pos_seq = []\n",
    "    neg_seq = []\n",
    "    for i in range(len(row.label_seq)):\n",
    "        if row.label_seq[i]==1:\n",
    "            pos_seq.append(row.itemid_seq[i])\n",
    "        else:\n",
    "            neg_seq.append(row.itemid_seq[i])\n",
    "    return pos_seq, neg_seq, len(row.itemid_seq), len(pos_seq), len(neg_seq)\n",
    "\n",
    "\n",
    "sequence_df[[\"pos_seq\",\"neg_seq\", \"seq_length\", \"pos_seq_length\", \"neg_seq_length\"]] = sequence_df.apply(get_seq, axis=1, result_type=\"expand\") \n",
    "sequence_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_df_fliter = sequence_df[(sequence_df[\"pos_seq_length\"]>=20) & (sequence_df[\"neg_seq_length\"]>=10)].reset_index(drop=True)\n",
    "item_df = item_df[item_df[\"itemid\"].isin(list(itertools.chain.from_iterable(sequence_df_fliter[\"itemid_seq\"].values.tolist())))].reset_index(drop=True)\n",
    "sequence_df_fliter\n",
    "item_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LabelEncoder \n",
    "from sklearn import preprocessing\n",
    "\n",
    "user_le = preprocessing.LabelEncoder()\n",
    "user_le.fit(sequence_df_fliter['userid'].values.tolist())\n",
    "print(\"user id unique nums:\", len(user_le.classes_))\n",
    "sequence_df_fliter['userid'] = pd.Series(user_le.transform(sequence_df_fliter['userid']))\n",
    "\n",
    "item_le = preprocessing.LabelEncoder()\n",
    "item_le.fit(list(itertools.chain.from_iterable(sequence_df_fliter[\"itemid_seq\"].values.tolist())))\n",
    "print(\"item id unique nums:\", len(item_le.classes_))\n",
    "sequence_df_fliter['pos_seq'] = sequence_df_fliter['pos_seq'].apply(lambda x: list(item_le.transform(x)))\n",
    "sequence_df_fliter['neg_seq'] = sequence_df_fliter['neg_seq'].apply(lambda x: list(item_le.transform(x)))\n",
    "\n",
    "sequence_df_fliter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_pop = item_pop[item_pop[\"itemid\"].isin(list(item_df['itemid'].values.tolist()))].reset_index(drop=True)\n",
    "item_pop[\"itemid\"] = pd.Series(item_le.transform(item_pop['itemid']))\n",
    "\n",
    "item_df[\"itemid\"] = pd.Series(item_le.transform(item_df['itemid']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_df.to_csv(f\"./Dataset/{dataset_name}/processed/full_item_df.csv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Gnerate Test Data for Top-K Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_df(df, n):\n",
    "    df_new = copy.deepcopy(df)\n",
    "    df_new[\"pos_seq\"] = df_new[\"pos_seq\"].apply(lambda x: x[:-n]) \n",
    "    df_new[\"pos_seq_length\"] = df_new[\"pos_seq\"].apply(lambda x:len(x))\n",
    "\n",
    "    return df_new\n",
    "\n",
    "sequence_df_fliter[\"data_index\"] = sequence_df_fliter[\"userid\"].apply(lambda x: 0)\n",
    "sequence_df_fliter_list = [sequence_df_fliter]\n",
    "for i in range(1, 10):\n",
    "    sequence_df_fliter_new = get_new_df(sequence_df_fliter, i)\n",
    "    sequence_df_fliter_new[\"data_index\"] = sequence_df_fliter_new[\"userid\"].apply(lambda x: i)\n",
    "    sequence_df_fliter_list.append(sequence_df_fliter_new)\n",
    "    \n",
    "full_sequence_df = pd.concat(sequence_df_fliter_list).reset_index(drop=True)\n",
    "full_sequence_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(2023)\n",
    "\n",
    "def get_pos_neg_target(row):\n",
    "\n",
    "    return row.pos_seq[-1], row.neg_seq[-1]\n",
    "\n",
    "\n",
    "def get_full_candidate(row, n_candidate):\n",
    "    cache = copy.deepcopy(row.neg_seq)\n",
    "    cache.remove(row.neg_id_target)\n",
    "    candidate = [row.pos_id_target] + [row.neg_id_target] + (random.sample(cache, n_candidate-2))\n",
    "    random.shuffle(candidate)\n",
    "    \n",
    "    return candidate\n",
    "\n",
    "\n",
    "def get_sub_candidate(row, n_candidate):\n",
    "    cand_cache = copy.deepcopy(row.full_candidate)\n",
    "    cand_cache.remove(row.pos_id_target)\n",
    "    cand_cache.remove(row.neg_id_target) \n",
    "    candidate = [row.pos_id_target] + [row.neg_id_target] + (random.sample(list(cand_cache), n_candidate-2))\n",
    "    random.shuffle(candidate)\n",
    "    \n",
    "    return candidate\n",
    "\n",
    "\n",
    "def get_full_history(row, n_history):\n",
    "    history = row.pos_seq[-1-n_history : -1]\n",
    "    return history\n",
    "\n",
    "\n",
    "def get_sub_history(row, n_history):\n",
    "    history = row.full_history[0-n_history : ]\n",
    "    return history\n",
    "\n",
    "def get_pos_target_index(row):\n",
    "    return row[\"itemid_candidate\"].index(row[\"pos_id_target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_sequence_df_new = full_sequence_df[[\"userid\",\"pos_seq\",\"neg_seq\",\"data_index\"]]\n",
    "full_sequence_df_new[[\"pos_id_target\", \"neg_id_target\"]] = full_sequence_df_new.apply(get_pos_neg_target, axis=1, result_type=\"expand\")\n",
    "full_sequence_df_new[\"full_candidate\"] = full_sequence_df_new.apply(get_full_candidate, n_candidate=10, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full_sequence_df_new[\"full_history\"] = full_sequence_df_new.apply(get_full_history, n_history=10, axis=1)\n",
    "full_sequence_df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_sequence_df_new.to_csv(f\"./Dataset/{dataset_name}/processed/full_sequence_df.csv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairwise_data(row):\n",
    "    candidate = row.itemid_candidate\n",
    "    pos = candidate[row.pos_target_index]\n",
    "    neg_list = copy.deepcopy(candidate)\n",
    "    neg_list.remove(pos)\n",
    "    pair_list = []\n",
    "    answer_list = []\n",
    "    for neg in neg_list:\n",
    "        pair = [pos, neg]\n",
    "        random.shuffle(pair)\n",
    "        answer = pair.index(pos)\n",
    "        pair_list.append(pair)\n",
    "        answer_list.append(answer)\n",
    "    \n",
    "    return pair_list, answer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topk_final_data(df):\n",
    "    for n_candidate in [2,5,10]:\n",
    "        for n_history in [1,3,5,10]:\n",
    "            print(f\"n_candidate:{n_candidate} ; n_history{n_history}\")\n",
    "            LLM_top1_data = copy.deepcopy(df)\n",
    "            LLM_top1_data[\"itemid_candidate\"] = LLM_top1_data.apply(get_sub_candidate, n_candidate=n_candidate, axis=1)\n",
    "            LLM_top1_data[\"itemid_history\"] = LLM_top1_data.apply(get_sub_history, n_history=n_history, axis=1)\n",
    "            LLM_top1_data[\"pos_target_index\"] = LLM_top1_data.apply(get_pos_target_index, axis=1)\n",
    "            LLM_top1_data = LLM_top1_data.sample(frac=1.0, random_state=2023).reset_index(drop=True)\n",
    "            LLM_top1_data[[\"pair_itemid_candidate\", \"pair_pos_target_index\"]] = LLM_top1_data.apply(get_pairwise_data, axis=1, result_type=\"expand\")\n",
    "            LLM_top1_data.to_csv(f\"./Dataset/{dataset_name}/LLM/topk_candidate@{n_candidate}_history@{n_history}.csv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_topk_final_data(full_sequence_df_new)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Generate Datamaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_name(s):\n",
    "    s = s.replace(\"&amp;\", \"&\")\n",
    "    s = s.replace(\"  \", \" \")\n",
    "    s = s.replace(\"\\n\", \" \")\n",
    "    s = s.replace(\"\\\\\", \" \")\n",
    "    return s\n",
    "item_df[\"title\"] = item_df[\"title\"].apply(lambda x: process_name(x))\n",
    "item_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2item_dict = item_df.set_index(\"itemid\")[\"title\"].to_dict()\n",
    "id2item_dict\n",
    "item2id_dict = item_df.set_index(\"title\")[\"itemid\"].to_dict()\n",
    "item2id_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamaps = {}\n",
    "datamaps[\"id2item_dict\"] = id2item_dict\n",
    "datamaps[\"item2id_dict\"] = item2id_dict\n",
    "\n",
    "import json\n",
    "json_str = json.dumps(datamaps)\n",
    "with open(f\"./Dataset/{dataset_name}/LLM/datamaps.json\", 'w') as out:\n",
    "    out.write(json_str)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item2pop_dict = item_pop.set_index(\"itemid\")[\"pop\"].to_dict()\n",
    "for i in id2item_dict.keys():\n",
    "    if i not in item2pop_dict.keys():\n",
    "        item2pop_dict[i] = 0\n",
    "item2pop_dict\n",
    "\n",
    "json_str = json.dumps(item2pop_dict)\n",
    "with open(f\"./Dataset/{dataset_name}/LLM/popularity_datamaps.json\", 'w') as out:\n",
    "    out.write(json_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of Loading Final Evaluation Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>itemid_history</th>\n",
       "      <th>pos_target_index</th>\n",
       "      <th>itemid_candidate</th>\n",
       "      <th>pair_itemid_candidate</th>\n",
       "      <th>pair_pos_target_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>368</td>\n",
       "      <td>[27737, 27781, 27790, 27796, 27826]</td>\n",
       "      <td>2</td>\n",
       "      <td>[28426, 21108, 27850, 16683, 13451]</td>\n",
       "      <td>[[27850, 28426], [27850, 21108], [16683, 27850], [13451, 27850]]</td>\n",
       "      <td>[0, 0, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>208</td>\n",
       "      <td>[4186, 6194, 8744, 11293, 23311]</td>\n",
       "      <td>2</td>\n",
       "      <td>[20267, 18222, 23529, 2581, 25927]</td>\n",
       "      <td>[[23529, 20267], [23529, 18222], [2581, 23529], [25927, 23529]]</td>\n",
       "      <td>[0, 0, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>216</td>\n",
       "      <td>[26957, 28656, 6368, 3468, 25025]</td>\n",
       "      <td>3</td>\n",
       "      <td>[30264, 22236, 30606, 4696, 18873]</td>\n",
       "      <td>[[30264, 4696], [4696, 22236], [4696, 30606], [4696, 18873]]</td>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>345</td>\n",
       "      <td>[4590, 18403, 18497, 19024, 10122]</td>\n",
       "      <td>4</td>\n",
       "      <td>[24564, 5935, 6284, 18015, 9256]</td>\n",
       "      <td>[[9256, 24564], [9256, 5935], [9256, 6284], [18015, 9256]]</td>\n",
       "      <td>[0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>317</td>\n",
       "      <td>[5386, 175, 2460, 2415, 6867]</td>\n",
       "      <td>2</td>\n",
       "      <td>[8835, 19746, 7714, 2169, 25016]</td>\n",
       "      <td>[[8835, 7714], [7714, 19746], [7714, 2169], [7714, 25016]]</td>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9085</th>\n",
       "      <td>398</td>\n",
       "      <td>[29512, 3807, 29575, 29657, 22694]</td>\n",
       "      <td>2</td>\n",
       "      <td>[2767, 19867, 17303, 28289, 29067]</td>\n",
       "      <td>[[2767, 17303], [19867, 17303], [28289, 17303], [29067, 17303]]</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9086</th>\n",
       "      <td>595</td>\n",
       "      <td>[6055, 20687, 20256, 14337, 16046]</td>\n",
       "      <td>2</td>\n",
       "      <td>[16335, 21952, 20674, 12043, 15151]</td>\n",
       "      <td>[[20674, 16335], [21952, 20674], [20674, 12043], [20674, 15151]]</td>\n",
       "      <td>[0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9087</th>\n",
       "      <td>16</td>\n",
       "      <td>[5407, 5813, 10697, 13929, 3645]</td>\n",
       "      <td>2</td>\n",
       "      <td>[3342, 5437, 15959, 1635, 3534]</td>\n",
       "      <td>[[3342, 15959], [15959, 5437], [1635, 15959], [3534, 15959]]</td>\n",
       "      <td>[1, 0, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>203</td>\n",
       "      <td>[7728, 11668, 9318, 23837, 896]</td>\n",
       "      <td>3</td>\n",
       "      <td>[27678, 24409, 22184, 22454, 6852]</td>\n",
       "      <td>[[27678, 22454], [24409, 22454], [22454, 22184], [22454, 6852]]</td>\n",
       "      <td>[1, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9089</th>\n",
       "      <td>406</td>\n",
       "      <td>[28018, 28156, 28328, 28160, 27905]</td>\n",
       "      <td>2</td>\n",
       "      <td>[26769, 27124, 28331, 27772, 25304]</td>\n",
       "      <td>[[26769, 28331], [28331, 27124], [28331, 27772], [28331, 25304]]</td>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9090 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      userid                       itemid_history  pos_target_index  \\\n",
       "0        368  [27737, 27781, 27790, 27796, 27826]                 2   \n",
       "1        208     [4186, 6194, 8744, 11293, 23311]                 2   \n",
       "2        216    [26957, 28656, 6368, 3468, 25025]                 3   \n",
       "3        345   [4590, 18403, 18497, 19024, 10122]                 4   \n",
       "4        317        [5386, 175, 2460, 2415, 6867]                 2   \n",
       "...      ...                                  ...               ...   \n",
       "9085     398   [29512, 3807, 29575, 29657, 22694]                 2   \n",
       "9086     595   [6055, 20687, 20256, 14337, 16046]                 2   \n",
       "9087      16     [5407, 5813, 10697, 13929, 3645]                 2   \n",
       "9088     203      [7728, 11668, 9318, 23837, 896]                 3   \n",
       "9089     406  [28018, 28156, 28328, 28160, 27905]                 2   \n",
       "\n",
       "                         itemid_candidate  \\\n",
       "0     [28426, 21108, 27850, 16683, 13451]   \n",
       "1      [20267, 18222, 23529, 2581, 25927]   \n",
       "2      [30264, 22236, 30606, 4696, 18873]   \n",
       "3        [24564, 5935, 6284, 18015, 9256]   \n",
       "4        [8835, 19746, 7714, 2169, 25016]   \n",
       "...                                   ...   \n",
       "9085   [2767, 19867, 17303, 28289, 29067]   \n",
       "9086  [16335, 21952, 20674, 12043, 15151]   \n",
       "9087      [3342, 5437, 15959, 1635, 3534]   \n",
       "9088   [27678, 24409, 22184, 22454, 6852]   \n",
       "9089  [26769, 27124, 28331, 27772, 25304]   \n",
       "\n",
       "                                                 pair_itemid_candidate  \\\n",
       "0     [[27850, 28426], [27850, 21108], [16683, 27850], [13451, 27850]]   \n",
       "1      [[23529, 20267], [23529, 18222], [2581, 23529], [25927, 23529]]   \n",
       "2         [[30264, 4696], [4696, 22236], [4696, 30606], [4696, 18873]]   \n",
       "3           [[9256, 24564], [9256, 5935], [9256, 6284], [18015, 9256]]   \n",
       "4           [[8835, 7714], [7714, 19746], [7714, 2169], [7714, 25016]]   \n",
       "...                                                                ...   \n",
       "9085   [[2767, 17303], [19867, 17303], [28289, 17303], [29067, 17303]]   \n",
       "9086  [[20674, 16335], [21952, 20674], [20674, 12043], [20674, 15151]]   \n",
       "9087      [[3342, 15959], [15959, 5437], [1635, 15959], [3534, 15959]]   \n",
       "9088   [[27678, 22454], [24409, 22454], [22454, 22184], [22454, 6852]]   \n",
       "9089  [[26769, 28331], [28331, 27124], [28331, 27772], [28331, 25304]]   \n",
       "\n",
       "     pair_pos_target_index  \n",
       "0             [0, 0, 1, 1]  \n",
       "1             [0, 0, 1, 1]  \n",
       "2             [1, 0, 0, 0]  \n",
       "3             [0, 0, 0, 1]  \n",
       "4             [1, 0, 0, 0]  \n",
       "...                    ...  \n",
       "9085          [1, 1, 1, 1]  \n",
       "9086          [0, 1, 0, 0]  \n",
       "9087          [1, 0, 1, 1]  \n",
       "9088          [1, 1, 0, 0]  \n",
       "9089          [1, 0, 0, 0]  \n",
       "\n",
       "[9090 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_example_df = pd.read_csv(f\"./Dataset/{dataset_name}/LLM/topk_candidate@5_history@5.csv\", delimiter=\"\\t\")\n",
    "read_example_df = read_example_df[[\"userid\", \"itemid_history\", \"pos_target_index\", \"itemid_candidate\", \"pair_itemid_candidate\", \"pair_pos_target_index\"]]\n",
    "for col in ['itemid_history', 'itemid_candidate', \"pair_itemid_candidate\", \"pair_pos_target_index\"]:\n",
    "    read_example_df[col] = read_example_df[col].apply(lambda x: eval(x))\n",
    "    \n",
    "read_example_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28426, 21108, 27850, 16683, 13451],\n",
       "       [20267, 18222, 23529,  2581, 25927],\n",
       "       [30264, 22236, 30606,  4696, 18873],\n",
       "       ...,\n",
       "       [ 3342,  5437, 15959,  1635,  3534],\n",
       "       [27678, 24409, 22184, 22454,  6852],\n",
       "       [26769, 27124, 28331, 27772, 25304]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_example_df = pd.read_csv(f\"./Dataset/{dataset_name}/LLM/topk_candidate@5_history@5.csv\", delimiter=\"\\t\")\n",
    "read_example_df = read_example_df[[\"userid\", \"pos_target_index\", \"itemid_candidate\"]]\n",
    "read_example_df[\"itemid_candidate\"] = read_example_df[\"itemid_candidate\"].apply(lambda x: x[1:-1])\n",
    "candidate = read_example_df['itemid_candidate'].str.split(',', expand=True)\n",
    "for col in candidate.columns:\n",
    "    candidate[col] = candidate[col].apply(lambda x: int(x))\n",
    "candidate.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_1_6",
   "language": "python",
   "name": "torch_1_6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
